{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 63,
            "source": [
                "import pytorch_lightning as pl\r\n",
                "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\r\n",
                "import torch\r\n",
                "import torch.nn as nn\r\n",
                "from torch.optim import SGD\r\n",
                "from torch.utils.data import DataLoader\r\n",
                "from torchvision import transforms\r\n",
                "from torchvision.datasets import ImageFolder\r\n",
                "from torchvision import models\r\n",
                "class Net(pl.LightningModule):\r\n",
                "    def __init__(\r\n",
                "        self,\r\n",
                "        model,\r\n",
                "        batch_size,\r\n",
                "        epochs,\r\n",
                "        data_path=\"data/debug\",\r\n",
                "        lr=1e-4\r\n",
                "    ):\r\n",
                "        super(Net,self).__init__()\r\n",
                "        self.batch_size = batch_size\r\n",
                "        self.epochs = epochs\r\n",
                "        self.data_path=data_path[:-1] if data_path[-1]==\"/\" else data_path\r\n",
                "        self.lr = lr\r\n",
                "        self.model=model\r\n",
                "        self.loss_fn=nn.CrossEntropyLoss()\r\n",
                "    def forward(\r\n",
                "        self,x\r\n",
                "    ):\r\n",
                "        o=self.model(x)\r\n",
                "        return o\r\n",
                "    def train_dataloader(self) :\r\n",
                "        return DataLoader(\r\n",
                "            ImageFolder(\r\n",
                "                self.data_path+\"/train\",\r\n",
                "                transform=transforms.Compose(\r\n",
                "                    [\r\n",
                "                        transforms.ToTensor(),\r\n",
                "                        transforms.RandomResizedCrop([224,224]),\r\n",
                "                    ]\r\n",
                "                )\r\n",
                "            ),\r\n",
                "            batch_size=self.batch_size,\r\n",
                "            shuffle=True,\r\n",
                "            drop_last=True,\r\n",
                "            num_workers=4,\r\n",
                "        )\r\n",
                "    def val_dataloader(self) :\r\n",
                "        return DataLoader(\r\n",
                "            ImageFolder(\r\n",
                "                self.data_path+\"/valid\",\r\n",
                "                transform=transforms.Compose(\r\n",
                "                    [transforms.ToTensor(),transforms.Resize([224,224])]\r\n",
                "                )\r\n",
                "            ),\r\n",
                "            batch_size=self.batch_size,\r\n",
                "            shuffle=True,\r\n",
                "            drop_last=True,\r\n",
                "            num_workers=4,\r\n",
                "        )    \r\n",
                "    def configure_optimizers(self):\r\n",
                "        optimizer = SGD(self.parameters(), lr=self.lr, weight_decay=0.001)\r\n",
                "        return optimizer\r\n",
                "    def training_step(self, batch, batch_nb):\r\n",
                "        pred = self.forward(batch[0])\r\n",
                "        loss=self.loss_fn(pred,batch[1])\r\n",
                "        self.log(\r\n",
                "            \"train_loss\",\r\n",
                "            loss,\r\n",
                "            on_step=True,\r\n",
                "            on_epoch=True,\r\n",
                "            prog_bar=True,\r\n",
                "            logger=True,\r\n",
                "        )\r\n",
                "        return loss\r\n",
                "    def validation_step(self, batch, batch_nb):\r\n",
                "        pred = self.forward(batch[0])\r\n",
                "        loss=self.loss_fn(pred,batch[1])\r\n",
                "        return loss\r\n",
                "    def validation_epoch_end(self, outputs):\r\n",
                "        avg_loss = torch.stack(outputs).mean()\r\n",
                "        self.log(\r\n",
                "            \"val_loss\",\r\n",
                "            avg_loss,\r\n",
                "            on_epoch=True,\r\n",
                "            prog_bar=True,\r\n",
                "            logger=True,\r\n",
                "        )\r\n",
                "        return {\"val_loss\": avg_loss}"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": []
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "source": [
                "if __name__=='__main__':\r\n",
                "    epochs=10\r\n",
                "    output_path=\"runs/exp1\"\r\n",
                "    batch_size=2\r\n",
                "    data_path=\"data/debug\"\r\n",
                "    lr=1e-3\r\n",
                "    checkpoint_callback = ModelCheckpoint(\r\n",
                "        dirpath=output_path,\r\n",
                "        verbose=True,\r\n",
                "        every_n_epochs=1,\r\n",
                "        save_top_k=1,\r\n",
                "        monitor=\"val_loss\",\r\n",
                "        mode=\"min\",\r\n",
                "    )\r\n",
                "    trainer = pl.Trainer(\r\n",
                "        default_root_dir=output_path,\r\n",
                "        gradient_clip_val=1,\r\n",
                "        max_epochs=epochs,\r\n",
                "        gpus=1,\r\n",
                "        callbacks=[checkpoint_callback],\r\n",
                "        precision=32,\r\n",
                "        progress_bar_refresh_rate=50\r\n",
                "    )\r\n",
                "    net = Net(\r\n",
                "        models.resnet18(pretrained=True),\r\n",
                "        batch_size,\r\n",
                "        epochs,\r\n",
                "        data_path=data_path,\r\n",
                "        lr=lr,\r\n",
                "    )\r\n",
                "    trainer.fit(net)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "C:\\Users\\pikachu_wcg\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:446: UserWarning: Checkpoint directory runs/exp1 exists and is not empty.\n",
                        "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
                        "GPU available: True, used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name    | Type             | Params\n",
                        "---------------------------------------------\n",
                        "0 | model   | ResNet           | 11.7 M\n",
                        "1 | loss_fn | CrossEntropyLoss | 0     \n",
                        "---------------------------------------------\n",
                        "11.7 M    Trainable params\n",
                        "0         Non-trainable params\n",
                        "11.7 M    Total params\n",
                        "46.758    Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "C:\\Users\\pikachu_wcg\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:372: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
                        "  rank_zero_warn(\n",
                        "C:\\Users\\pikachu_wcg\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 0:   0%|          | 0/136 [00:00<00:00, 500.93it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "C:\\Users\\pikachu_wcg\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
                        "  rank_zero_warn(\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 0: 100%|██████████| 136/136 [00:10<00:00, 12.50it/s, loss=8.81, v_num=7, train_loss_step=8.950, val_loss=11.20]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 0, global step 67: val_loss reached 11.17545 (best 11.17545), saving model to \"C:\\VScode\\deep_learning\\ifly_pic\\runs\\exp1\\epoch=0-step=67.ckpt\" as top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1: 100%|██████████| 136/136 [00:10<00:00, 13.56it/s, loss=8.36, v_num=7, train_loss_step=8.430, val_loss=11.00, train_loss_epoch=8.720]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 1, global step 135: val_loss reached 11.02602 (best 11.02602), saving model to \"C:\\VScode\\deep_learning\\ifly_pic\\runs\\exp1\\epoch=1-step=135.ckpt\" as top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 2: 100%|██████████| 136/136 [00:11<00:00, 11.66it/s, loss=8.46, v_num=7, train_loss_step=9.320, val_loss=10.80, train_loss_epoch=8.510]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 2, global step 203: val_loss reached 10.83526 (best 10.83526), saving model to \"C:\\VScode\\deep_learning\\ifly_pic\\runs\\exp1\\epoch=2-step=203.ckpt\" as top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 3: 100%|██████████| 136/136 [00:10<00:00, 12.48it/s, loss=8.75, v_num=7, train_loss_step=9.490, val_loss=11.20, train_loss_epoch=8.520]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 3, global step 271: val_loss was not in top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 4: 100%|██████████| 136/136 [00:10<00:00, 13.65it/s, loss=8.15, v_num=7, train_loss_step=8.690, val_loss=11.00, train_loss_epoch=8.600]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 4, global step 339: val_loss was not in top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 5: 100%|██████████| 136/136 [00:09<00:00, 14.03it/s, loss=8.64, v_num=7, train_loss_step=8.570, val_loss=10.90, train_loss_epoch=8.530]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 5, global step 407: val_loss was not in top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 6: 100%|██████████| 136/136 [00:10<00:00, 12.78it/s, loss=8.75, v_num=7, train_loss_step=9.740, val_loss=11.20, train_loss_epoch=8.670]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 6, global step 475: val_loss was not in top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 7: 100%|██████████| 136/136 [00:10<00:00, 12.64it/s, loss=8.66, v_num=7, train_loss_step=7.450, val_loss=11.10, train_loss_epoch=8.870]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 7, global step 543: val_loss was not in top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 8: 100%|██████████| 136/136 [00:09<00:00, 13.85it/s, loss=8.48, v_num=7, train_loss_step=6.870, val_loss=11.20, train_loss_epoch=8.470]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 8, global step 611: val_loss was not in top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 9: 100%|██████████| 136/136 [00:09<00:00, 14.01it/s, loss=8.77, v_num=7, train_loss_step=8.560, val_loss=11.00, train_loss_epoch=8.470]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Epoch 9, global step 679: val_loss was not in top 1\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 9: 100%|██████████| 136/136 [00:09<00:00, 13.99it/s, loss=8.77, v_num=7, train_loss_step=8.560, val_loss=11.00, train_loss_epoch=8.470]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.8 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "40c4e17f077218d16613fe0a521debfb2207e39289331d3ad681e8733da961f0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}